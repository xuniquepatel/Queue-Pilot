# Distributed-Task-Scheduling-System
A scalable, fault-tolerant, and concurrent task execution system built using **Python**, **Flask**, and **Redis**. This system dynamically distributes tasks across multiple worker nodes, ensures reprocessing on worker failure, and features a dashboard for real-time monitoring.

---

## ğŸ”§ Features

- âœ… **Distributed Workers** â€“ Run multiple workers in parallel to handle tasks.
- âŸ² **Fault Tolerance** â€“ Heartbeat-based health checks and auto-requeue of tasks if a worker fails.
- âš–ï¸ **Load Balancing** â€“ Tasks are assigned to the least loaded active worker using Redis queues.
- ğŸ” **Real-Time Dashboard** â€“ Web interface to submit and monitor tasks across queues and workers.
- ğŸ“¦ **Queue Architecture** â€“ Uses a dual-queue setup: a `task_queue` for pending tasks and `processing:*` queues per worker.
- ğŸ§  **Monitor Node** â€“ Requeues stuck tasks from failed workers.

---

## ğŸ“‚ Project Structure

```
distributed-task-scheduling-system/
|
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ client_interface/
â”‚   â”‚   â””â”€â”€ api.py              # Flask API for submitting and tracking tasks
â”‚   â”œâ”€â”€ master_node/
â”‚   â”‚   â””â”€â”€ scheduler.py        # Scheduler assigns tasks based on load
â”‚   â”œâ”€â”€ monitor/
â”‚   â”‚   â””â”€â”€ monitor.py          # Monitor detects dead workers and requeues tasks
â”‚   â”œâ”€â”€ task_queue/
â”‚   â”‚   â””â”€â”€ redis_queue.py      # Redis queue logic (BRPOPLPUSH, LREM)
â”‚   â”œâ”€â”€ worker_node/
â”‚   â”‚   â””â”€â”€ worker.py           # Worker that processes tasks and sends heartbeats
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ logger.py           # Logging utility
â”‚   â””â”€â”€ venv/                   # Python virtual environment
|
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ dashboard.html          # Real-time dashboard interface
```

---

## ğŸš€ How It Works

1. **Submit a task** using the dashboard or API.
2. **Master Node** checks worker heartbeats and assigns tasks to the least-loaded.
3. Task is **pushed to the worker's `processing:<id>` queue**.
4. **Worker** picks task, processes it, removes from queue.
5. If worker fails, **Monitor** detects via stale heartbeat and requeues the task to `task_queue`.
6. **Dashboard** updates every 3 seconds from `/queue_status` API.

---

## ğŸ’¡ Key Components

- **Master Node (Scheduler):** Handles assignment of tasks to workers using live Redis stats.
- **Worker Nodes:** Fetch and execute tasks, and send periodic heartbeats.
- **Redis Queues:** `task_queue` for incoming tasks and `processing:<worker_id>` queues for in-process tasks.
- **Monitor Node:** Detects heartbeat expiry and safely requeues unprocessed tasks.
- **Dashboard:** User interface for submitting and monitoring tasks in real time.

---

## ğŸ§ª Setup Instructions

### 1. Clone Repository
```bash
git clone https://github.com/your-username/distributed-task-scheduling-system.git
cd distributed-task-scheduling-system/backend
```

### 2. Setup Virtual Environment
```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 3. Run Redis
Make sure Redis is installed and running on localhost:6379.
```bash
brew install redis
redis-server
```

### 4. Start Each Component
Run these in separate terminals:

#### Master Scheduler
```bash
export PYTHONPATH=$(pwd)
python -m master_node.scheduler
```

#### Monitor Node
```bash
python -m monitor.monitor
```

#### Worker Nodes
```bash
WORKER_INDEX=1 python -m worker_node.worker
WORKER_INDEX=2 python -m worker_node.worker
```

#### Flask API
```bash
python -m client_interface.api
```

#### Frontend Dashboard
```bash
cd frontend
python3 -m http.server 9090
```
Visit: `http://localhost:9090/dashboard.html`

---

## ğŸ“Š Dashboard Screenshot



## ğŸŒ REST API Endpoints

| Endpoint         | Method | Description                      |
|------------------|--------|----------------------------------|
| `/submit_task`   | POST   | Submit a new task to scheduler   |
| `/queue_status`  | GET    | View pending tasks & worker info |
| `/system_status` | GET    | Internal system-wide state       |

---

## ğŸ“ Concepts Used

- Multithreaded task submission
- Redis-backed persistent queues
- Worker heartbeat monitoring
- Fault recovery (auto-reassignment)
- Load-based task distribution

---

## ğŸ¤– Future Enhancements

- Task retry limit / exponential backoff
- Store results to database
- WebSocket live dashboard
- Docker-based deployment
- RESTful logs & history endpoints

---

## âœï¸ Authors

**Team 14 - IT559 Distributed Systems Project**  
- Kahan Mehta (202411038)  
- Unique Patel (202411013)  
- Manav Rathod (202411057)  

---

## ğŸ“š License

This project is intended for academic demonstration under IT559 Distributed Systems, Spring 2025.

